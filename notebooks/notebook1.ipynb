{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Clinical-Informatics-Interest-Group/CLiC.notebooks/blob/main/notebooks/uci_diabetes_data.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hospital Readmission Data\n",
    "\n",
    "An original publication with the dataset we will explore investigated the impact of HbA1c measurement in hospital readmission rates by modeling the relationship with a multivariable logistic regression.\n",
    "\n",
    "The open dataset is provided by the University of California Irvine here\n",
    "https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008\n",
    "\n",
    "The original publication of data source\n",
    "https://www.hindawi.com/journals/bmri/2014/781670/\n",
    "\n",
    "Publication authors description of the data.\n",
    "https://www.hindawi.com/journals/bmri/2014/781670/tab1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first cell is reserved for importing useful libraries that we\n",
    "# will need for machine learning and working with lots of data.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile, requests, io #We'll use these to get and extract the data from its repository\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block to download the data into the working directory.\n",
    "# In Colab, this is a directory on the cloud within your google drive.\n",
    "# The 'get_data' function checks to see if the data has already been download\n",
    "# and downloads it if not.\n",
    "def get_data():\n",
    "    if Path('./dataset_diabetes/diabetic_data.csv').is_file():\n",
    "        pass\n",
    "    else:\n",
    "        r = requests.get('https://archive.ics.uci.edu/ml/machine-learning-databases/00296/dataset_diabetes.zip')\n",
    "        z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "        z.extractall()\n",
    "        \n",
    "get_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the variable \"df\" to the pandas DataFrame containing our data.\n",
    "df = pd.read_csv('./dataset_diabetes/diabetic_data.csv')\n",
    "df.head() # Calling the first 5 rows of the data to have a first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask pandas if it knows any of the data samples are duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the class labels to decide if any na-values should be dropped\n",
    "for col in df.columns[2:]:\n",
    "    print(col, 'labels:', np.unique(df[col]), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see some of the data entries are '?'. Let's encode this so that python knows these are missing data. \n",
    "df = pd.read_csv('./dataset_diabetes/diabetic_data.csv', na_values=['?'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last block threw an interesting error. We'll investigate this shortly with \"df.dtypes()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can find the number of samples missing data for each feature\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already knew the data was missing some values. See https://www.hindawi.com/journals/bmri/2014/781670/tab1/\n",
    "\n",
    "We will have to consider whether to drop these feature columns all together. Just to be sure how many \"samples\" we have, let's check the total number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
